# Big Data Project

This project focuses on working with big data using PySpark. It involves executing queries on RDD (Resilient Distributed Datasets) and DataFrame APIs, as well as reading and writing data in CSV and Parquet formats.

## Project Structure

---
## In Progress && To-Do

- [x] **Implementations**
    - [x] Part 1
        - [x] Implementation
        - [x] Save query execution-times 
        - [x] Save query-output
    - [x] Part 2
        - [x] Join types
        - [x] SQL optimiser
- [ ] **Putting it all together**
    - [ ] Complete writing the report
        - [x] Finish first draft
        - [ ] Editing
	- [ ] Configure `README.md`
		- [ ] Instructions to run locally	
		- [ ] Code explanation and overview
